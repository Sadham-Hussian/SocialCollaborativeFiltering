# -*- coding: utf-8 -*-
"""TrustMF_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b5VNOzMh-iO6-x6paKI42SxNsuXMb_ot

### Import Packages & Define Constants:
"""

from google.colab import drive
drive.mount('/content/drive')
# drive.mount('/content/drive', force_remount=True)

!ls

import torch
from torch.autograd import Variable
from torch import optim
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import time

R_max = 5 # Maximum rating value possible
M = 49289  # No. of users in Epinions Dataset
N = 139738  # No. of items in Epinions Dataset
D = 10 # Dimensionality of latent space for users and items
lamda = 0.001 # Hyperparameter for loss function

"""### Read Epinions Dataset into Ratings Matrix and Trust Matrix:"""

ratings_file = "drive/My Drive/SCFT_Project/data/epinions_ratings_data.txt"
trust_file = "drive/My Drive/SCFT_Project/data/standardized_epinions_trust_data.txt"

def read_ratings_data():
    global ratings_file
    ratings_data = pd.read_csv(ratings_file, sep=" ", header=None)
    ratings_data.columns = ["user_id", "item_id", "rating"]
    return ratings_data

ratings_data = read_ratings_data()

ratings_data["rating"] /= R_max
convert_dict = {"user_id": int,
                "item_id": int,
                "rating": float}
ratings_data = ratings_data.astype(convert_dict)
print(ratings_data.dtypes)

ratings_data.head(4)

ratings_data.tail(4)

def read_trust_data():
    global trust_file
    trust_data = pd.read_csv(trust_file, sep=" ", header=None)
    trust_data.columns = ["user1_id", "user2_id", "trust_val"]
    return trust_data

trust_data = read_trust_data()

trust_data.head(4)

trust_data.tail(4)

TRAIN_RATIO = 0.80 # Ratio of training to validation set

ratings_data_train, ratings_data_test = train_test_split(ratings_data, train_size=TRAIN_RATIO, shuffle=True, random_state=19)

print(len(ratings_data_train))
print(len(ratings_data_test))

ratings_data_train.head(5)

ratings_data_train.tail(5)

ratings_data_test.head(5)

ratings_data_test.tail(5)

"""### Train Truster Model:"""

torch.manual_seed(42) # Set any random seed for reproducibility
# Browse Reviews Behaviour Matrix (Influence from other users)- Approximates User feature matrix U in Truster Model
B_trusterMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True) 
# Item feature matrix
V_trusterMF = Variable(torch.empty((D, N)).normal_(mean=0.0, std=0.1), requires_grad=True) 
# Write Reviews Behaviour Matrix (Influence other users)
W_trusterMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)

# nbi - no. of ratings given by user i
# nvj - no. of ratings given to item j
def calculate_nbi_and_nvj():
    global ratings_data_train, M, N
    nbi = np.zeros(M)
    nvj = np.zeros(N)
    for idx in range(len(ratings_data_train)):
        nbi[int(ratings_data_train.iloc[idx]["user_id"])-1] += 1
        nvj[int(ratings_data_train.iloc[idx]["item_id"])-1] += 1
    return nbi, nvj

# mbi - no. of users who are trusted by user i
# mwk - no. of users who trust user k
def calculate_mbi_and_mwk():
    global trust_data, M
    mbi = np.zeros(M)
    mwk = np.zeros(M)
    for idx in range(len(trust_data)):
        mbi[trust_data.iloc[idx]["user1_id"]-1] += 1
        mwk[trust_data.iloc[idx]["user2_id"]-1] += 1
    return mbi, mwk

# start = time.time()
# nbi, nvj = calculate_nbi_and_nvj()
# end = time.time()
# print(end-start, " seconds")

#np.save('drive/My Drive/SCFT_Project/npy_files/nbi.npy', nbi)
# # nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
#np.save('drive/My Drive/SCFT_Project/npy_files/nvj.npy', nvj)
# # nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')

# start = time.time()
# mbi, mwk = calculate_mbi_and_mwk()
# end = time.time()
# print(end-start, " seconds")

# np.save('drive/My Drive/SCFT_Project/npy_files/mbi.npy', mbi)
# # mbi = np.load('drive/My Drive/SCFT_Project/npy_files/mbi.npy')
# np.save('drive/My Drive/SCFT_Project/npy_files/mwk.npy', mwk)
# # mwk = np.load('drive/My Drive/SCFT_Project/npy_files/mwk.npy')

# nbi - no. of ratings given by user i
nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
# nvj - no. of ratings given to item j
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
# mbi - no. of users who are trusted by user i
mbi = np.load('drive/My Drive/SCFT_Project/npy_files/mbi.npy')
# mwk - no. of users who trust user k
mwk = np.load('drive/My Drive/SCFT_Project/npy_files/mwk.npy')

epochs = 2 # No. of epochs
alpha_lr = 0.005 # Learning rate
optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)

for iteration in range(0, 0+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

B_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusterMF_"+str(1)+".pth"), requires_grad=True)
V_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusterMF_"+str(1)+".pth"), requires_grad=True)
W_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusterMF_"+str(1)+".pth"), requires_grad=True)

nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mbi = np.load('drive/My Drive/SCFT_Project/npy_files/mbi.npy')
mwk = np.load('drive/My Drive/SCFT_Project/npy_files/mwk.npy')

epochs = 4
alpha_lr = 0.4
optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)

for iteration in range(2, 2+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

B_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusterMF_"+str(5)+".pth"), requires_grad=True)
V_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusterMF_"+str(5)+".pth"), requires_grad=True)
W_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusterMF_"+str(5)+".pth"), requires_grad=True)
nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mbi = np.load('drive/My Drive/SCFT_Project/npy_files/mbi.npy')
mwk = np.load('drive/My Drive/SCFT_Project/npy_files/mwk.npy')

epochs = 2
alpha_lr = 0.4
optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)

for iteration in range(6, 6+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

epochs = 2
alpha_lr = 0.25
optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)

for iteration in range(8, 8+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

epochs = 2

for iteration in range(10, 10+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusterMF_11.pth")

epochs = 2

for iteration in range(12, 12+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusterMF_13.pth")

nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mbi = np.load('drive/My Drive/SCFT_Project/npy_files/mbi.npy')
mwk = np.load('drive/My Drive/SCFT_Project/npy_files/mwk.npy')
B_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusterMF_"+str(13)+".pth"), requires_grad=True)
V_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusterMF_"+str(13)+".pth"), requires_grad=True)
W_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusterMF_"+str(13)+".pth"), requires_grad=True)

epochs = 3
alpha_lr = 0.20
optimizer = optim.SGD([B_trusterMF, V_trusterMF, W_trusterMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusterMF_13.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(14, 17):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusterMF[:, user1_id-1], W_trusterMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nbi[user_id]+mbi[user_id]) * (B_trusterMF[:, user_id].pow(2).sum()))
        reg_loss += (mwk[user_id] * (W_trusterMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusterMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (4) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusterMF, "drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration)+".pth")
    torch.save(V_trusterMF, "drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration)+".pth")
    torch.save(W_trusterMF, "drive/My Drive/SCFT_Project/W_trusterMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusterMF_16.pth")

"""### Train Trustee Model:"""

torch.manual_seed(42) # Set any random seed for reproducibility
# Browse Reviews Behaviour Matrix (Influence from other users)
B_trusteeMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)
# Item feature matrix
V_trusteeMF = Variable(torch.empty((D, N)).normal_(mean=0.0, std=0.1), requires_grad=True)
# Write Reviews Behaviour Matrix (Influence other users) - Approximates User feature matrix U in Trustee Model
W_trusteeMF = Variable(torch.empty((D, M)).normal_(mean=0.0, std=0.1), requires_grad=True)

# nwi - no. of ratings given by user i
# nvj - no. of ratings given to item j
def calculate_nwi_and_nvj():
    global ratings_data_train, M, N
    nwi = np.zeros(M)
    nvj = np.zeros(N)
    for idx in range(len(ratings_data_train)):
        nwi[int(ratings_data_train.iloc[idx]["user_id"])-1] += 1
        nvj[int(ratings_data_train.iloc[idx]["item_id"])-1] += 1
    return nwi, nvj

# mbk - no. of users who are trusted by user k
# mwi - no. of users who trust user i
def calculate_mwi_and_mbk():
    global trust_data, M
    mwi = np.zeros(M)
    mbk = np.zeros(M)
    for idx in range(len(trust_data)):
        mwi[trust_data.iloc[idx]["user2_id"]-1] += 1
        mbk[trust_data.iloc[idx]["user1_id"]-1] += 1
    return mwi, mbk

start = time.time()
nwi, nvj = calculate_nwi_and_nvj()
end = time.time()
print(end-start, " seconds")

np.save('drive/My Drive/SCFT_Project/npy_files/nwi.npy', nwi)
# nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
np.save('drive/My Drive/SCFT_Project/npy_files/nvj.npy', nvj)
# nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')

start = time.time()
mwi, mbk = calculate_mwi_and_mbk()
end = time.time()
print(end-start, " seconds")

np.save('drive/My Drive/SCFT_Project/npy_files/mwi.npy', mwi)
# mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
np.save('drive/My Drive/SCFT_Project/npy_files/mbk.npy', mbk)
# mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 6 # No. of epochs
alpha_lr = 0.4 # Learning Rate
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)

for iteration in range(0, 0+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_5.pth")

epochs = 4
alpha_lr = 0.25
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr

for iteration in range(6, 6+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(8)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(8)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(8)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 3
alpha_lr = 0.20
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_5.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(9, 9+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(10)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(10)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(10)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 4
alpha_lr = 0.10
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_5.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(11, 11+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_14.pth")

epochs = 4

for iteration in range(15, 15+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_18.pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(18)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(18)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(18)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 4
alpha_lr = 0.04
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_18.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(19, 19+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(20)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(20)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(20)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 4
alpha_lr = 0.08
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_18.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(21, 21+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_24.pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(24)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(24)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(24)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 4
alpha_lr = 0.08
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_24.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(25, 25+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_28.pth")

epochs = 4
alpha_lr = 0.1
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(29, 29+epochs):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_32.pth")

B_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusteeMF_"+str(32)+".pth"), requires_grad=True)
V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(32)+".pth"), requires_grad=True)
W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(32)+".pth"), requires_grad=True)
nwi = np.load('drive/My Drive/SCFT_Project/npy_files/nwi.npy')
nvj = np.load('drive/My Drive/SCFT_Project/npy_files/nvj.npy')
mwi = np.load('drive/My Drive/SCFT_Project/npy_files/mwi.npy')
mbk = np.load('drive/My Drive/SCFT_Project/npy_files/mbk.npy')

epochs = 2
alpha_lr = 0.2
optimizer = optim.SGD([B_trusteeMF, V_trusteeMF, W_trusteeMF], lr=alpha_lr)
checkpt = torch.load("drive/My Drive/SCFT_Project/optimizer_trusteeMF_32.pth")
optimizer.load_state_dict(checkpt)
print(optimizer.state_dict())
for pg in optimizer.param_groups:
    pg['lr'] = alpha_lr
print(optimizer.state_dict())

for iteration in range(33, 34):
    start = time.time()
    loss = torch.tensor(0.0)
    optimizer.zero_grad()
    for idx in range(len(ratings_data_train)):
        user_id = int(ratings_data_train.iloc[idx]["user_id"])
        item_id = int(ratings_data_train.iloc[idx]["item_id"])
        rating = ratings_data_train.iloc[idx]["rating"]
        loss += (torch.sigmoid(torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) - rating).pow(2)
    for idx in range(len(trust_data)):
        user1_id = trust_data.iloc[idx]["user1_id"]
        user2_id = trust_data.iloc[idx]["user2_id"]
        trust_val = trust_data.iloc[idx]["trust_val"]
        loss += (torch.sigmoid(torch.dot(B_trusteeMF[:, user1_id-1], W_trusteeMF[:, user2_id-1])) - trust_val).pow(2)
    reg_loss = torch.tensor(0.0)
    for user_id in range(M):
        reg_loss += ((nwi[user_id]+mwi[user_id]) * (W_trusteeMF[:, user_id].pow(2).sum()))
        reg_loss += (mbk[user_id] * (B_trusteeMF[:, user_id].pow(2).sum()))
    for item_id in range(N):
        reg_loss += (nvj[item_id] * (V_trusteeMF[:, item_id].pow(2).sum()))
    loss += (lamda * reg_loss)
    loss.backward() # Loss corresponding to Eq. (5) in the paper
    optimizer.step()
    end = time.time()
    print("Iteration: ", iteration, ", loss: ", loss, ", time(seconds): ", end-start)
    torch.save(B_trusteeMF, "drive/My Drive/SCFT_Project/B_trusteeMF_"+str(iteration)+".pth")
    torch.save(V_trusteeMF, "drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration)+".pth")
    torch.save(W_trusteeMF, "drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration)+".pth")

torch.save(optimizer.state_dict(), "drive/My Drive/SCFT_Project/optimizer_trusteeMF_34.pth")

"""### Predict Rating:"""

def get_model_parameters(iteration_r, iteration_e):
    B_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/B_trusterMF_"+str(iteration_r)+".pth"), requires_grad=False)
    V_trusterMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusterMF_"+str(iteration_r)+".pth"), requires_grad=False)
    W_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/W_trusteeMF_"+str(iteration_e)+".pth"), requires_grad=False)
    V_trusteeMF = Variable(torch.load("drive/My Drive/SCFT_Project/V_trusteeMF_"+str(iteration_e)+".pth"), requires_grad=False)
    model_dict = {'B_trusterMF': B_trusterMF, 'V_trusterMF': V_trusterMF, 'W_trusteeMF': W_trusteeMF, 'V_trusteeMF': V_trusteeMF}
    return model_dict

def predict_rating(model_dict, user_id, item_id):
    global R_max 
    B_trusterMF = model_dict['B_trusterMF']
    V_trusterMF = model_dict['V_trusterMF']
    W_trusteeMF = model_dict['W_trusteeMF']
    V_trusteeMF = model_dict['V_trusteeMF']
    prediction = R_max * (torch.sigmoid((torch.dot(B_trusterMF[:, user_id-1], V_trusterMF[:, item_id-1]) + torch.dot(W_trusteeMF[:, user_id-1], V_trusteeMF[:, item_id-1])) / 2))
    return prediction
    # return prediction.data

"""### Validation on All Users (Paper Section 4.3.1):"""

# Mean Absolute Error
def compute_MAE(model_dict, mode="train"):
    global ratings_data_train, ratings_data_test
    if mode == "train":
        data = ratings_data_train
    else:
        data = ratings_data_test
    AE = torch.tensor(0.0)
    for idx in range(len(data)):
        user_id = int(data.iloc[idx]["user_id"])
        item_id = int(data.iloc[idx]["item_id"])
        rating = (data.iloc[idx]["rating"]) * R_max
        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)
    MAE = AE / len(data)
    return MAE

# Root Mean Square Error
def compute_RMSE(model_dict, mode="train"):
    global ratings_data_train, ratings_data_test
    if mode == "train":
        data = ratings_data_train
    else:
        data = ratings_data_test
    SE = torch.tensor(0.0)
    for idx in range(len(data)):
        user_id = int(data.iloc[idx]["user_id"])
        item_id = int(data.iloc[idx]["item_id"])
        rating = (data.iloc[idx]["rating"]) * R_max
        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))
    MSE = SE / len(data)
    RMSE = torch.sqrt(MSE)
    return RMSE

model_dict = get_model_parameters(15, 33)

print(compute_MAE(model_dict, mode="train"))

print(compute_MAE(model_dict, mode="test"))

print(compute_RMSE(model_dict, mode="train"))

print(compute_RMSE(model_dict, mode="test"))

"""### Validation on Cold Start Users (Paper Section 4.3.2):"""

# Mean Absolute Error For Cold Start Users
def compute_MAE_cold_start(model_dict, mode="train", threshold=5):
    global ratings_data_train, ratings_data_test
    nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
    if mode == "train":
        data = ratings_data_train
    else:
        data = ratings_data_test
    AE = torch.tensor(0.0)
    cnt = 0
    for idx in range(len(data)):
        user_id = int(data.iloc[idx]["user_id"])
        if nbi[user_id-1] > threshold: # NOT A COLD START USER
            continue
        item_id = int(data.iloc[idx]["item_id"])
        rating = (data.iloc[idx]["rating"]) * R_max
        cnt += 1
        AE += torch.abs(predict_rating(model_dict, user_id, item_id) - rating)
    MAE = AE / cnt
    return MAE

# Root Mean Square Error For Cold Start Users
def compute_RMSE_cold_start(model_dict, mode="train", threshold=5):
    global ratings_data_train, ratings_data_test
    nbi = np.load('drive/My Drive/SCFT_Project/npy_files/nbi.npy')
    if mode == "train":
        data = ratings_data_train
    else:
        data = ratings_data_test
    SE = torch.tensor(0.0)
    cnt = 0
    for idx in range(len(data)):
        user_id = int(data.iloc[idx]["user_id"])
        if nbi[user_id-1] > threshold: # NOT A COLD START USER
            continue
        item_id = int(data.iloc[idx]["item_id"])
        rating = (data.iloc[idx]["rating"]) * R_max
        cnt += 1
        SE += ((predict_rating(model_dict, user_id, item_id) - rating).pow(2))
    MSE = SE / cnt
    RMSE = torch.sqrt(MSE)
    return RMSE

model_dict = get_model_parameters(15, 33)

print(compute_MAE_cold_start(model_dict, mode="train"))

print(compute_MAE_cold_start(model_dict, mode="test"))

print(compute_RMSE_cold_start(model_dict, mode="train"))

print(compute_RMSE_cold_start(model_dict, mode="test"))

"""### References:

##### Epinions Dataset:
http://www.trustlet.org/downloaded_epinions.html
"""